# Initial configuration â€“ will expand.

llm:
  provider: "openai"      # "openai" | "ollama"
  openai:
    model: "gpt-4o-mini"
    temperature: 0.2
  ollama:
    host: "http://localhost:11434"
    model: "mistral"

stripe:
  enabled: false          # set true in prod
  currency: "aud"
